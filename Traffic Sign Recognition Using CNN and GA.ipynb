{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6qXVilpa0t1",
        "outputId": "23377d93-6bf1-44f8-d655-e1d1ad835a06"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "wbsZOG8hbJtu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "classes = 43  # Number of classes\n",
        "cur_path = os.getcwd()\n",
        "\n",
        "# Retrieve images and labels\n",
        "for i in range(classes):\n",
        "    path = os.path.join('/content/drive/MyDrive/GTSRB','Train', str(i))\n",
        "    images = os.listdir(path)\n",
        "    for img in images:\n",
        "        try:\n",
        "            image = Image.open(path + '/' + img)\n",
        "            image = image.resize((30, 30))  # Resize to 30x30\n",
        "            image = np.array(image)\n",
        "            data.append(image)\n",
        "            labels.append(i)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "Stw6w17WbLRu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n"
      ],
      "metadata": {
        "id": "04FeKx4vbM0K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deap\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO1h2THIbOlO",
        "outputId": "167a142c-2136-4edc-e3bf-8101b4390417"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.26.4)\n",
            "Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "\n",
        "# Evaluation function for an individual\n",
        "def evaluate_individual(individual):\n",
        "    # Decode the hyperparameters\n",
        "    filters_1 = individual[0]\n",
        "    filters_2 = individual[1]\n",
        "    kernel_size = (individual[2], individual[2])\n",
        "    learning_rate = individual[3]\n",
        "    batch_size = individual[4]\n",
        "\n",
        "    # Define the CNN model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(filters=filters_1, kernel_size=(5, 5), activation='relu', input_shape=X_train.shape[1:]),\n",
        "        tf.keras.layers.Conv2D(filters=filters_2, kernel_size=kernel_size, activation='relu'),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model (reduced epochs for evaluation speed)\n",
        "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=3, validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "    # Get validation accuracy\n",
        "    val_accuracy = history.history['val_accuracy'][-1]\n",
        "    return val_accuracy,\n"
      ],
      "metadata": {
        "id": "46KsE7yDbQH4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))  # Maximize validation accuracy\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_filter1\", random.choice, [16, 32, 64, 128])  # Filters for the first Conv layer\n",
        "toolbox.register(\"attr_filter2\", random.choice, [16, 32, 64, 128])  # Filters for the second Conv layer\n",
        "toolbox.register(\"attr_kernel\", random.choice, [3, 5, 7])           # Kernel size\n",
        "toolbox.register(\"attr_lr\", random.uniform, 0.0001, 0.01)           # Learning rate\n",
        "toolbox.register(\"attr_batch\", random.choice, [16, 32, 64])         # Batch size\n",
        "\n",
        "# Individual and population\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 (toolbox.attr_filter1, toolbox.attr_filter2, toolbox.attr_kernel, toolbox.attr_lr, toolbox.attr_batch))\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# Genetic operators\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=128, indpb=0.2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"evaluate\", evaluate_individual)\n"
      ],
      "metadata": {
        "id": "YhpnfW1gbRtr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GA parameters\n",
        "population = toolbox.population(n=10)  # Initial population size\n",
        "NGEN = 5                               # Number of generations\n",
        "CXPB, MUTPB = 0.5, 0.2                # Crossover and mutation probabilities\n",
        "\n",
        "# Run the Genetic Algorithm\n",
        "for gen in range(NGEN):\n",
        "    print(f\"Generation {gen + 1}\")\n",
        "    # Evaluate all individuals\n",
        "    fitnesses = map(toolbox.evaluate, population)\n",
        "    for ind, fit in zip(population, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    # Select and generate new individuals\n",
        "    offspring = toolbox.select(population, len(population))\n",
        "    offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "    # Apply crossover and mutation\n",
        "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "        if random.random() < CXPB:\n",
        "            toolbox.mate(child1, child2)\n",
        "            del child1.fitness.values\n",
        "            del child2.fitness.values\n",
        "\n",
        "    for mutant in offspring:\n",
        "        if random.random() < MUTPB:\n",
        "            toolbox.mutate(mutant)\n",
        "            del mutant.fitness.values\n",
        "\n",
        "    # Replace population with next generation\n",
        "    population[:] = offspring\n",
        "\n",
        "# Best individual\n",
        "best_individual = tools.selBest(population, 1)[0]\n",
        "print(f\"Best hyperparameters: {best_individual}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GUUwdDObT-O",
        "outputId": "b3017d37-3f89-46f7-e1b5-327d084fdacb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 2\n",
            "Generation 3\n",
            "Generation 4\n",
            "Generation 5\n",
            "Best hyperparameters: [16, 93, 3, 0.003060158895301083, 27]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_filters_1 = best_individual[0]\n",
        "best_filters_2 = best_individual[1]\n",
        "best_kernel = (best_individual[2], best_individual[2])\n",
        "best_lr = best_individual[3]\n",
        "best_batch_size = best_individual[4]\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=best_filters_1, kernel_size=(5, 5), activation='relu', input_shape=X_train.shape[1:]),\n",
        "    tf.keras.layers.Conv2D(filters=best_filters_2, kernel_size=best_kernel, activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_lr),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=best_batch_size, epochs=15, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to0YXFm-bVrE",
        "outputId": "490f58d8-ea94-4768-e0a8-44bd175172ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6524 - loss: 1.3668 - val_accuracy: 0.9521 - val_loss: 0.1792\n",
            "Epoch 2/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.1103 - val_accuracy: 0.9685 - val_loss: 0.1187\n",
            "Epoch 3/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0738 - val_accuracy: 0.9549 - val_loss: 0.1946\n",
            "Epoch 4/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.0782 - val_accuracy: 0.9329 - val_loss: 0.4410\n",
            "Epoch 5/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.0836 - val_accuracy: 0.9741 - val_loss: 0.1085\n",
            "Epoch 6/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0527 - val_accuracy: 0.9764 - val_loss: 0.1611\n",
            "Epoch 7/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0538 - val_accuracy: 0.9791 - val_loss: 0.1188\n",
            "Epoch 8/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 0.0351 - val_accuracy: 0.9682 - val_loss: 0.2359\n",
            "Epoch 9/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0464 - val_accuracy: 0.9713 - val_loss: 0.2511\n",
            "Epoch 10/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0371 - val_accuracy: 0.9836 - val_loss: 0.1453\n",
            "Epoch 11/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 0.0562 - val_accuracy: 0.9806 - val_loss: 0.2031\n",
            "Epoch 12/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9916 - loss: 0.0534 - val_accuracy: 0.9832 - val_loss: 0.2312\n",
            "Epoch 13/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0499 - val_accuracy: 0.9758 - val_loss: 0.3213\n",
            "Epoch 14/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0585 - val_accuracy: 0.9762 - val_loss: 0.3435\n",
            "Epoch 15/15\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9938 - loss: 0.0501 - val_accuracy: 0.9829 - val_loss: 0.1911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('traffic_classifier_optimized.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKB75fUPbXd-",
        "outputId": "dbf0ca65-5cd5-4cb8-e4a6-0a580f78cf3a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('traffic_classifier_optimized.h5')\n",
        "\n",
        "# Define traffic sign labels\n",
        "classes = {\n",
        "    0: 'Speed limit (20km/h)', 1: 'Speed limit (30km/h)', 2: 'Speed limit (50km/h)',\n",
        "    3: 'Speed limit (60km/h)', 4: 'Speed limit (70km/h)', 5: 'Speed limit (80km/h)',\n",
        "    6: 'End of speed limit (80km/h)', 7: 'Speed limit (100km/h)', 8: 'Speed limit (120km/h)',\n",
        "    9: 'No passing', 10: 'No passing vehicles >3.5 metric tons', 11: 'Right of way at intersection',\n",
        "    12: 'Priority road', 13: 'Yield', 14: 'Stop', 15: 'No vehicles', 16: 'Vehicles >3.5 tons prohibited',\n",
        "    17: 'No entry', 18: 'General caution', 19: 'Dangerous curve left', 20: 'Dangerous curve right',\n",
        "    21: 'Double curve', 22: 'Bumpy road', 23: 'Slippery road', 24: 'Road narrows on the right',\n",
        "    25: 'Road work', 26: 'Traffic signals', 27: 'Pedestrians', 28: 'Children crossing',\n",
        "    29: 'Bicycles crossing', 30: 'Beware of ice/snow', 31: 'Wild animals crossing',\n",
        "    32: 'End of speed + passing limits', 33: 'Turn right ahead', 34: 'Turn left ahead',\n",
        "    35: 'Ahead only', 36: 'Go straight or right', 37: 'Go straight or left', 38: 'Keep right',\n",
        "    39: 'Keep left', 40: 'Roundabout mandatory', 41: 'End of no passing', 42: 'End no passing >3.5 tons'\n",
        "}\n",
        "\n",
        "# Function to predict a new image\n",
        "def predict_new_image(img_path):\n",
        "    img = Image.open(img_path).resize((30, 30))\n",
        "    img_array = np.expand_dims(np.array(img) / 255.0, axis=0)\n",
        "    prediction = np.argmax(model.predict(img_array))\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted: {classes[prediction]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    return classes[prediction]\n",
        "\n",
        "# Test with a new image\n",
        "img_path = '11623.png'  # Update with your image path\n",
        "predicted_class = predict_new_image(img_path)\n",
        "print(f\"The predicted class is: {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "5FzLEod9oTDB",
        "outputId": "7f72b7a7-e9cb-4d05-e900-958bfa7ad17e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class is: Road work\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}